---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 1.0.5
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Set up working environment

```{python}

import pandas as pd
import json
import requests
from bs4 import BeautifulSoup as BS
import re
import warnings
import bokeh
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import codecs
from json import JSONDecoder
from functools import partial
pd.options.display.max_rows = 999
pd.options.display.max_columns = 999
warnings.filterwarnings("ignore")
```

# Get data and save as pickle data types

```{python}
# user = pd.read_json('data\\user.json', lines=True)
# user.head()
# user.shape
# user.to_pickle("user.pkl")
# user.head()
```

```{python}
# checkin = pd.read_json('data\\checkin.json', lines=True)
# checkin.to_pickle("checkin.pkl")
# checkin.head()
# review = pd.read_json('data\\review.json', lines=True)
# review.to_pickle("review.pkl")
```

```{python}
# tip = pd.read_json('data\\tip.json', lines=True)
# tip.to_pickle("tip.pkl")
# tip.head()
```

```{python}
# business = pd.read_json('data\\business.json', lines=True)
# business.to_pickle("business.pkl")
# business.head()


```

```{python}
# photo = pd.read_json('data\\photo.json', lines=True)
# photo.to_pickle("photo.pkl")
# photo.head()
```

# subset datasets 


## review cleaning

```{python}
# review=pd.read_pickle("data\\review.pkl")
# review.shape

# review.head()

# review['stars']=review['stars'].astype(int)
# review['useful']=review['useful'].astype(float)
# review.info()

# review=review.loc[review['useful']>=2,:]


# review=review.loc[:,["business_id","stars","user_id"]]
# review.shape

# review.head()

# review.to_pickle("data\\review1")
```

## Business data slicing

```{python}
# business=pd.read_pickle('business.pkl')

# business.head()

# business['city'].value_counts()

# business=business.loc[(business['city']=='Las Vegas') & (business['review_count']>100),:]

# business=business.loc[:,["categories","business_id","name"]]

# business.to_pickle("data\\business1")
```

## user slicing

```{python}
# user=pd.read_pickle('data\\user.pkl')

# user.head()

# user.head()

# user=user.loc[:,['user_id','review_count','useful']]
# user.head()

# user.info()

# user=user.loc[(user['review_count']>60) & (user['useful']>10),:]
# user.shape

# user.to_pickle('data\\user1')
```

# Load data set and merge them

```{python}
user1=pd.read_pickle('data\\user.pkl')
user1.shape
```

```{python}
user1.head()
```

```{python}
review1=pd.read_pickle('data\\review1')
review1.shape
```

```{python}
review1.head()
```

```{python}
business1=pd.read_pickle('data\\business1')
business1.reset_index(inplace=True)

business1=business1.drop(["index"], axis=1)
business1.shape
```

```{python}
business1.head()
```

```{python}
business1=business1[["business_id","name","categories"]]
business1=business1.fillna(0)
```

```{python}
business1=business1.sort_values("business_id")
```

```{python}
business1.shape
```

```{python}
business1["movieId"] = business1.index + 1
```

```{python}
business1.head()
```

```{python}
business1.rename(columns={'name':'title','categories':'genres'})
```

```{python}
business_id_codes=business1[['business_id','movieId']]
business_id_codes.head()
```

```{python}
business1=business1.sort_values("movieId")
```

```{python}
business1=business1.drop(["business_id"], axis=1)
```

```{python}
business1=business1[["movieId","name","categories"]]
```

```{python}
business1.to_csv("data\\movies.csv")
```

```{python}
review1=pd.read_pickle('data\\review1')
review1.shape
```

```{python}
restaurant=pd.read_pickle('data\\business1')
restaurant.shape
```

```{python}
restaurant.head()
```

```{python}
ratings=pd.merge(restaurant,review1,on="business_id",how="inner")
```

```{python}
ratings=ratings.loc[:,["user_id","business_id","stars"]]
```

```{python}
ratings.head()
```

```{python}
ratings.shape
```

```{python}
user_id_code=ratings.drop_duplicates(subset=["user_id"], keep="first")
```

```{python}
user_id_code.shape
```

```{python}
user_id_code.reset_index(inplace=True)
```

```{python}
user_id_code["userId"]=user_id_code.index + 1
```

```{python}
user_id_code=user_id_code[["user_id","userId"]]
```

```{python}
user_id_code.head()
```

```{python}
ratings=pd.merge(user_id_code,ratings,on='user_id',how='inner')
```

```{python}
ratings=pd.merge(ratings,business_id_codes,on='business_id',how='inner')
```

```{python}
ratings=ratings[["userId","movieId","stars"]]
```

```{python}
ratings["timestamp"]=1260759144
```

```{python active="", eval=FALSE}
ratings.rename(columns={'stars':'rating'})
```

```{python}
ratings.head()
```

```{python}
ratings.to_csv("data\\ratings.csv")
```
